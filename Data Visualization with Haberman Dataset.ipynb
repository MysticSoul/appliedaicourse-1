{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3.12) Exercise:\n",
    "\n",
    "1. Download Haberman Cancer Survival dataset from Kaggle. You may have to create a Kaggle account to donwload data. (https://www.kaggle.com/gilsousa/habermans-survival-data-set)\n",
    "2. Perform a similar alanlaysis as above on this dataset with the following sections:\n",
    "* High level statistics of the dataset: number of points, numer of   features, number of classes, data-points per class.\n",
    "* Explain our objective. \n",
    "* Perform Univaraite analysis(PDF, CDF, Boxplot, Voilin plots) to understand which features are useful towards classification.\n",
    "* Perform Bi-variate analysis (scatter plots, pair-plots) to see if combinations of features are useful in classfication.\n",
    "* Write your observations in english as crisply and unambigously as possible. Always quantify your results.\n",
    "* Try to document every plot and every analysis you do, please refer attached notebook. Note: Upload both python notebook and pdf version of that notebook Check this: https://ipython.org/ipython-doc/3/notebook/nbconvert.html  to convert python notebooks to pdfs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization with Haberman Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-1: About Kaggle (the source of data) and tools exposed to download the dataset \n",
    "\n",
    "blurp on kaggle \n",
    "\n",
    "``` bash \n",
    "# create datasets directory, if exists skip mkdir \n",
    "mkdir -p datasets \n",
    "# download the dataset via kaggle api call  \n",
    "kaggle datasets download -d gilsousa/habermans-survival-data-set\n",
    "mv *.zip ./datasets/\n",
    "# unzip datasets/habermans-survival-data-set.zip \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haberman.csv                    habermans-survival-data-set.zip\r\n"
     ]
    }
   ],
   "source": [
    " !ls datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "filepath=\"/Users/krishna/Desktop/appliedaicourse/datasets/haberman.csv\"\n",
    "\n",
    "#Load haberman.csv into a pandas dataFrame.\n",
    "haberman = pd.read_csv(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>30</th>\n",
       "      <th>64</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   30  64   1  1.1\n",
       "0  30  62   3    1\n",
       "1  30  65   0    1\n",
       "2  31  59   2    1\n",
       "3  31  65   4    1\n",
       "4  33  58  10    1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haberman.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30,64,1,1\n",
      "30,62,3,1\n",
      "30,65,0,1\n",
      "31,59,2,1\n",
      "31,65,4,1\n",
      "33,58,10,1\n",
      "33,60,0,1\n",
      "34,59,0,2\n",
      "34,66,9,2\n",
      "34,58,30,1\n",
      "     306 /Users/krishna/Desktop/appliedaicourse/datasets/haberman.csv\n"
     ]
    }
   ],
   "source": [
    "!head /Users/krishna/Desktop/appliedaicourse/datasets/haberman.csv\n",
    "!wc -l /Users/krishna/Desktop/appliedaicourse/datasets/haberman.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
